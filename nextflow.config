/*
 * -------------------------------------------------
 *  nf-core/mhcquant Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

// Global default params, used in configs
params {

  // Workflow flags
  outdir = './results'
  publish_dir_mode = 'copy'

  // Boilerplate options
  multiqc_config = false
  email = false
  email_on_fail = false
  plaintext_email = false
  monochrome_logs = false
  help = false

  tracedir = "${params.outdir}/pipeline_info"
  multiqc_config = false
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames = false
  config_profile_name = null
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false
  show_hidden_params = true
  validate_params = true

  publish_dir_mode = 'copy'
  enable_conda = false
  max_multiqc_email_size     = '25.MB'
  skip_multiqc = true
  
  config_profile_name = false

  // workflow options
  help = false
  input = "sample_sheet.tsv"
  fasta = "data/*.fasta"
  allele_sheet = false
  predict_class_1 = false
  predict_class_2 = false
  refine_fdr_on_predicted_subset = false
  subset_affinity_threshold = 500
  include_proteins_from_vcf = false
  skip_decoy_generation = false
  subset_affinity_threshold = 500
  variant_reference = "GRCH38"
  variant_annotation_style = "SNPEFF"
  variant_indel_filter = false
  variant_frameshift_filter = false
  variant_snp_filter = false
  outdir = './results'
  schema_ignore_params = 'genomes,input_paths'

  // workflow defaults
  peptide_min_length = 8
  peptide_max_length = 12
  fragment_mass_tolerance = 0.02
  precursor_mass_tolerance = 5
  fragment_bin_offset = 0
  fdr_threshold = 0.01
  fdr_level = 'peptide-level-fdrs'
  refine_fdr_on_predicted_subset = false
  description_correct_features = 0
  number_mods = 3
  num_hits = 1
  digest_mass_range = "800:2500"
  pick_ms_levels = 2
  run_centroidisation = false
  prec_charge = '2:3'
  activation_method = 'ALL'
  enzyme = 'unspecific cleavage'
  fixed_mods = ''
  max_rt_alignment_shift = 300
  spectrum_batch_size = 500
  vcf_sheet = false
  variable_mods = 'Oxidation (M)'
  tracedir = "${params.outdir}/pipeline_info"
  description_correct_features = 0
  subset_max_train = 0
  klammer = false
  predict_RT = false
  use_x_ions = false
  use_z_ions = false
  use_a_ions = false
  use_c_ions = false
  use_NL_ions = false
  remove_precursor_peak = false
  skip_quantification = false
  quantification_fdr = false
  quantification_min_prob = 0

  // Options: Custom config
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false

  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Load nf-core custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

profiles {
  conda {
    docker.enabled = false
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud = false
    process.conda = "$projectDir/environment.yml"
  }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker {
    docker.enabled = true
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    // Avoid this error:
    //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
    // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
    // once this is established and works well, nextflow might implement this behavior as new default.
    // NOTE: This breaks MHCFlurry!
    // docker.runOptions = '-u \$(id -u):\$(id -g)'
  }
  singularity {
    docker.enabled = false
    singularity.enabled = true
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    singularity.autoMounts = true
  }
  podman {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = true
    shifter.enabled = false
    charliecloud = false
  }
  shifter {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = true
    charliecloud.enabled = false
  }
  charliecloud {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = true
  }
  test { includeConfig 'conf/test.config' }
  test_full { includeConfig 'conf/test_full.config' }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}

manifest {
  name = 'nf-core/mhcquant'
  author = 'Leon Bichmann'
  homePage = 'https://github.com/nf-core/mhcquant'
  description = 'Identify and quantify peptides from mass spectrometry raw data'
  mainScript = 'main.nf'
  nextflowVersion = '>=21.04.0'
  version = '2.0.0dev'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
